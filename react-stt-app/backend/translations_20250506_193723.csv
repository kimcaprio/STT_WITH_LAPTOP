timestamp,original,translated
2025-05-06 19:35:46.184023,"One cool thing about supervised learning is that it's not useful for one thing, it's useful for all of these different applications and many more besides.","감독 학습의 멋진 점 중 하나는 특정 한 가지에 유용한 것이 아니라, 다양한 여러 응용 분야에 모두 유용하며 그 이상의 것에도 적용 가능하다는 것입니다."
2025-05-06 19:35:53.194237,"walk through, you know, concretely the workflow of one example of a supervised learning, labeling things kind of project. If you want to build a system to label restaurant","예를 들어 감독 학습의 실제 워크플로를 구체적으로 살펴보세요. 가령 레스토랑 라벨링 시스템을 구축하고자 한다면, 데이터 수집부터 시작해 라벨링 프로세스, 모델 학습 및 검증까지의 전 과정을 경험해 보세요."
2025-05-06 19:36:00.747327,"reviews, you then collect a few data points or collect a data set. Where say, you know, the best time is I wish great to say that this positive, civil slow, this","리뷰를 수집한 후, 몇 가지 데이터 포인트를 모으거나 데이터 세트를 수집합니다. 예를 들어, 가장 좋은 시기는 긍정적이고 친절하며 천천히 말씀드리는 것이라고 말씀드리고 싶습니다."
2025-05-06 19:36:07.293456,"negative. My favorite chip and curry is positive. And here I've shown three data points, but you're building this, you may get thousands of data points.","부정적입니다. 제가 좋아하는 칩과 커리는 긍정적입니다. 여기 세 개의 데이터 포인트를 보여드렸지만, 당신이 이것을 구축한다면 수천 개의 데이터 포인트를 얻을 수 있을 것입니다."
2025-05-06 19:36:13.607426,"the points like this, thousands of training examples we call it, and the workflow of a machine learning project, an AI project is you get labeled data, maybe thousands of","이렇게 수천 개의 학습 예시와 같은 점들, 그리고 머신러닝 프로젝트, 즉 AI 프로젝트의 워크플로우는 라벨링된 데이터를 얻는 것으로 시작됩니다. 아마도 수천 개의..."
2025-05-06 19:36:19.709934,"data points, then you have an AI Android team train an AI model to learn from this data. And then finally you would find maybe a cloud service","데이터 포인트를 제공하면, AI 안드로이드 팀이 이 데이터로부터 학습하는 AI 모델을 훈련시킬 수 있습니다. 그리고 마지막으로 클라우드 서비스를 찾아볼 수 있습니다."
2025-05-06 19:36:27.784541,"to run the trained AI model and they can feed it, you know, the responsibility I've ever had and that's positive sentiment. And so I think the last day,","훈련된 AI 모델을 실행하고, 거기에 제가 지금까지 맡아온 책임감을 먹이는 거죠. 그래서 긍정적인 감정이에요. 그리고 마지막 날에는..."
2025-05-06 19:36:38.474837,"decade was maybe the decade of large-scale supervised learning. What we found starting about 10, 15 years ago was if you were to train a small","10~15년 전부터 발견한 것은, 만약 소규모의 모델을 훈련시킨다면"
2025-05-06 19:36:47.486039,"AI model. So train a small neural network or small deep learning algorithm. Basically, a small AI model, maybe not on a very powerful computer. Then as you fed more data,",인공지능 모델이니 작은 신경망이나 작은 딥러닝 알고리즘을 훈련시켜 보세요. 기본적으로 강력한 컴퓨터가 아니라 간단한 AI 모델로 시작하면 됩니다. 그런 다음 더 많은 데이터를 제공하면서 점차 향상시켜 나가세요.
2025-05-06 19:36:54.683253,"its performance would get better for a little bit but then it would flatten out, it would plateau and it would stop being able to use the data to get better and better.","성능은 잠깐 향상될 것입니다. 하지만 그 후로는 더 이상 개선되지 않고, 평평해져서 더 이상 데이터를 활용해 지속적으로 향상될 수 없게 될 것입니다."
2025-05-06 19:37:04.139153,"But if you were to train a very large AI model, lots of compute on maybe powerful GPUs, then as we scaled up the amount of data we get.","그러나 매우 큰 규모의 AI 모델을 학습시킨다면, 강력한 GPU 등 많은 연산력이 필요할 것입니다. 데이터 양이 증가함에 따라 이렇게 되는 것입니다."
2025-05-06 19:37:12.642282,"the machine learning model is performed to kind of keep on getting better and better. So this is why when I started and led the Google Brain team, the primary mission","머신러닝 모델은 지속적으로 더 나아지도록 설계되었습니다. 그래서 제가 구글 브레인 팀을 시작하고 이끌었을 때, 주요 목표는

(번역 완료)"
2025-05-06 19:37:23.072488,"that I directed the team to solve at the time was let's just build really, really large neural networks that we then fed a lot of data to and that recipe fortunately worked.",당시 제가 팀에 지시한 것은 엄청나게 큰 신경망을 구축하고 그에 방대한 양의 데이터를 제공하는 것이었습니다. 다행히도 그 방법이 잘 작동했습니다.
